<!DOCTYPE html>
<html lang="en" >
<head>
  <meta charset="UTF-8">
  <title>Neuroscience</title>
  <link rel="stylesheet" href="./resources/style.css">
  <link rel='stylesheet' href='./resources/ds_style.css'>

</head>
<body>
  <!-- partial:index.partial.html -->
  <body>
    <div id="mySidenav" class="sidenav">
      <a href="javascript:void(0)" class="closebtn" onclick="closeNav()">&times;</a>
      <p><a href="index.html">Home</a></p>
      <p><a href="ds.html">Data Science</a></p>
      <p><a href="neuro.html">Neuroscience</a></p>
    </div>

    <div id='main'>
      <span style="position:fixed;padding:40px;font-size:30px;cursor:pointer" onclick="openNav()">&#9776;</span>
      <div class="center-text">
        <div class="section-1">
          <h1 style="font-size: 35px;">Neuroscience</h1>
        </div>
        <div class="paragaph" style="margin-left:11px">
          <button type="button" class="collapsible">About Me <i class="fa fa-caret-down"></i></button>
          <div class="content">
            <p>I pursued data science because most of my favorite neuroscience studies involved machine
            learning and an emphasis on reproducible analytical pipelines and good coding practices.
            Similarly, I became a neuroscientist because I was studying philosophy
            of mind and most of my favorite philosophical work was being written by neuroscientists.
            <br>
            <br>
            During my graduate and postdoctoral research in neuroscience, I was lucky to have access to almost
            unlimited resources, good mentors, and brilliant colleagues. Here are some of the topics 
            and techniques I worked with:
            <ul>
              <li>Working with brain damaged patients who have fascinating higher-order disorders
                of perception and movement, such as visual form agnosia, neglect, and apraxia.</li>
              <li>Using transcranial magnetic stimulation (TMS) to perturb movement planning</li>
              <li>Using fMRI and EEG to study how the brain predicts how comfortable a future movement will be</li>
              <li>Measuring eye movements in humans, monkeys, and mice in order to understand how the 
                brain transforms visual information into plans for action.</li>
              <li>Sticking wire electrodes into chest muscles and recording visual (yes, visual) 
                activity while people reach toward targets.</li>
              <li>Using 3D motion capture to reveal that reaching trajectories can act as a "read-out"
                of real-time sensorimotor decision-making (e.g., choosing the brighter target or the target
                that gives you a bigger reward).</li>
              <li>Learning how the brain models the physics of objects by measuring the anticipatory fingertip forces people 
                apply when lifting those objects.
              </li>
              <li>Training monkeys and mice to play in virtual environments! :)</li>
            </ul>
            </p>
          </div>
          <br>
          You can find my neuro-centric curriculum vitae and a gallery of a few of my neuroscience 
          projects below.      
          <br>
          <br>   
        </div>

        <a href="./resources/files/Neuro_CV.pdf" style="text-decoration: none;">
          <div class="cvbutton">
            curriculum vitae
          </div>
        </a>
        <hr>
        <div class="section-1" style="padding-top:0px">
          <h3 style="font-size:22px">A gallery of neuroscience projects</h3>
        </div>
        <hr>
        <ul class="c-links" id="demo">
          <li class="btn--corners">
            <a href="https://github.com/danielkentwood/NERF">Predictive visual remapping in prefrontal cortex depends on saccadic intention</a>
            <p>In primates, the frontal eye field (FEF) is an area in the prefrontal cortex that is involved in planning and executing eye movements. Many of the neurons in this area also respond to visual stimulation. Each visual FEF cell has a receptive field--i.e., a part of space to which the cell becomes maximally active when a visual event happens. For decades, scientists assumed that these receptive fields were simply locked to the retina, so that they would just move as soon as the eye moved. Recently, studies have demonstrated that these receptive fields jump toward their future location before the eye starts moving, as if they "know" in advance where the eye movement will land. There is disagreement about how this remapping of the receptive fields occurs. This study aims to understand how the ultimate goal of the eye movement influences how the remapping process unfolds.</p>
          </li>
          <li class="btn--corners">
            <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/ejn.12976">Visually evoked activity in chest muscles resets the phase of physiological tremor</a>
            <p>We recorded muscle activity from pectoral muscles while subjects rapidly reached toward a flashed target. We observed a low-latency burst of directionally tuned muscle activity that was locked to the onset of the visual stimulus, not the onset of the movement. In other words, the muscle was was responding to the visual target before the subject had time to voluntarily respond. We also noted that physiological tremor (a subtle shaking that all healthy people exhibit) was "reset" by the onset of the visually evoked activity.</p>
          </li>
          <li class="btn--corners">
            <a href="https://www.sciencedirect.com/science/article/pii/S0010945216301940">Sensitivity to biomechanical limitations during postural decision-making depends on the integrity of posterior superior parietal cortex</a>
            <p>In most cases, when we want to pick up an object, there is one general posture that is most comfortable, and many other possible postures that would be possible but very uncomfortable. But when all of the potential ways of picking up an object are equally uncomfortable, how do humans decide which one to use? We use fMRI to ask which parts of the brain are involved, and how they represent the level of "motor ambiguity" involved in a task. We also show that when the area most heavily involved (i.e., posterior superior parietal cortex) is compromised in brain-damaged patients, it results in a larger range of circumstances where the patient has difficulty deciding how to best pick up the object.</p>
          </li>
          <li class="btn--corners">
            <a href="https://jov.arvojournals.org/article.aspx?articleid=2121022">Visual salience dominates early visuomotor competition in reaching behavior</a>
            <p>Suppose you have a touch screen full of empty circles, all of which are potential targets. Now suppose that as soon as those circles appear on the screen, you have to instantly start reaching toward them, even before you know what the final target will be. As soon as you start reaching, one of the circles fills in, letting you know that it is the final target. You must then correct your reach trajectory to touch the final target. Previously, my collaborators and I showed that the number of targets on each side of the screen influences the initial trajectory of the reach. When there are equal numbers of targets on each side, trajectories tend to go up the middle. The bigger the difference in targets, the more the initial trajectory is biased toward the side with more targets. In this study, we show that when you make one set of targets really bright and conspicuous, the reach trajectory is drawn toward them, even if there are more potential targets on the other side of space.</p>
          </li>
        </ul>
      </div>
    </div>

    <!-- JS scripts -->
    <script>
      function openNav() {
        document.getElementById("mySidenav").style.width = "175px";
        // document.getElementById("main").style.marginLeft = "250px";
      }
      function closeNav() {
        document.getElementById("mySidenav").style.width = "0";
        document.getElementById("main").style.marginLeft= "0";
      }
    </script>
    <script>
      var coll = document.getElementsByClassName("collapsible");
      var i;
      
      for (i = 0; i < coll.length; i++) {
        coll[i].addEventListener("click", function() {
          this.classList.toggle("active");
          var content = this.nextElementSibling;
          if (content.style.display === "block") {
            content.style.display = "none";
          } else {
            content.style.display = "block";
          }
        });
      }
      </script>
  </body>
  <!-- partial -->
  
</body>
</html>
